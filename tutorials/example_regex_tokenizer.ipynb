{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom tokenizer\n",
    "This notebook serves as a comparison between `nltk.tokenize.word_tokenizer` (what is currently used in `pvops`) and a custom regex-based tokenizer in an attempt to remove the `nltk` dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "# Default pattern identifies blocks of contiguous non-alphanumeric non-whitespace characters\n",
    "# that have whitespace on at least one side (i.e. are not interior to words or numbers)\n",
    "def regex_tokenize(doc, pattern=r'(?<=\\w)([^\\w\\s]+)(?=\\s)|(?<=\\s)([^\\w\\s]+)(?=\\w)'):\n",
    "    \n",
    "    # Temporarily buffer the document with spaces\n",
    "    doc = ' ' + doc + ' '\n",
    "\n",
    "    # Buffer anything matching the pattern with spaces on either side\n",
    "    doc = re.sub(pattern, r' \\1\\2 ', doc)\n",
    "\n",
    "    # replace any contiguous whitespace with a single space\n",
    "    doc = re.sub(r'\\s+', ' ', doc)\n",
    "\n",
    "    # remove leading and ending whitespace; break into tokens along spaces\n",
    "    return doc.strip().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('example_data/example_ML_ticket_data.csv')\n",
    "docs = df['CompletionDesc'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform tokenization and comapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokens = [word_tokenize(doc) for doc in docs]\n",
    "regex_tokens = [regex_tokenize(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 1. \tcb 1.18 was found to have contactor issue would not close the contactor was cycled terminated.. output was verified 126.1a combiner box output also verified with c4. techdispatched: yes\n",
      "nltk: \tcb 1.18 was found to have contactor issue would not close the contactor was cycled terminated .. output was verified 126.1a combiner box output also verified with c4 . techdispatched : yes\n",
      "regex: \tcb 1.18 was found to have contactor issue would not close the contactor was cycled terminated .. output was verified 126.1a combiner box output also verified with c4 . techdispatched : yes\n",
      "\n",
      "doc 2. \tself resolved. techdispatched: no\n",
      "nltk: \tself resolved . techdispatched : no\n",
      "regex: \tself resolved . techdispatched : no\n",
      "\n",
      "doc 3. \tall module rows washed, waiting for final report from sun power.\n",
      "nltk: \tall module rows washed , waiting for final report from sun power .\n",
      "regex: \tall module rows washed , waiting for final report from sun power .\n",
      "\n",
      "doc 4. \t14 nov: we were alerted that e-c3-1 had faulted by upon investigation, we noticed that inverter was indeed faulted out but was still communicating. we opened up inverter inspected pebb's, controls, breakers hmi. there were no issues found. we cycled inverter it began producing as expected.. techdispatched: no\n",
      "nltk: \t14 nov : we were alerted that e-c3-1 had faulted by upon investigation , we noticed that inverter was indeed faulted out but was still communicating . we opened up inverter inspected pebb 's , controls , breakers hmi . there were no issues found . we cycled inverter it began producing as expected .. techdispatched : no\n",
      "regex: \t14 nov : we were alerted that e-c3-1 had faulted by upon investigation , we noticed that inverter was indeed faulted out but was still communicating . we opened up inverter inspected pebb's , controls , breakers hmi . there were no issues found . we cycled inverter it began producing as expected .. techdispatched : no\n",
      "\n",
      "doc 5. \tassessed condition filters all inverters. little to no cleaning was needed across site.. techdispatched: no\n",
      "nltk: \tassessed condition filters all inverters . little to no cleaning was needed across site .. techdispatched : no\n",
      "regex: \tassessed condition filters all inverters . little to no cleaning was needed across site .. techdispatched : no\n",
      "\n",
      "doc 6. \tinverter 11 was showing fault 6422 via scada. inverter 11 was still up producing when i arrived to perform cycle but was not reporting any data via display through scada. inverter 11 was then cycled communication issues were resolved. inverter 11 is online producing. ticket# 401911247. techdispatched: no\n",
      "nltk: \tinverter 11 was showing fault 6422 via scada . inverter 11 was still up producing when i arrived to perform cycle but was not reporting any data via display through scada . inverter 11 was then cycled communication issues were resolved . inverter 11 is online producing . ticket # 401911247. techdispatched : no\n",
      "regex: \tinverter 11 was showing fault 6422 via scada . inverter 11 was still up producing when i arrived to perform cycle but was not reporting any data via display through scada . inverter 11 was then cycled communication issues were resolved . inverter 11 is online producing . ticket # 401911247 . techdispatched : no\n",
      "\n",
      "doc 7. \t[no completion notes were entered servicemax]. techdispatched: no\n",
      "nltk: \t[ no completion notes were entered servicemax ] . techdispatched : no\n",
      "regex: \t[ no completion notes were entered servicemax ]. techdispatched : no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_print = 7\n",
    "\n",
    "for i in range(num_print):\n",
    "    ntlk_doc = ' '.join(nltk_tokens[i])\n",
    "    regex_doc = ' '.join(regex_tokens[i])\n",
    "    print(f'doc {i+1}. \\t{docs[i]}')\n",
    "    print(f'nltk: \\t{ntlk_doc}')\n",
    "    print(f'regex: \\t{regex_doc}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
